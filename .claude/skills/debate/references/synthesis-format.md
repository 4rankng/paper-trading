# Prediction Output Format

Standardized template for truth-seeking debate predictions.

---

## Complete Output Template

```markdown
# Debate: [Specific Question]

**Date:** YYYY-MM-DD
**Personas:** [N] ([List roles])
**Rounds:** [N]
**Convergence:** [X%]
**Confidence:** [High/Medium/Low/Research Needed]

---

## Executive Summary (100 words max)

[Question] → [Prediction] with [X% probability].

[Key causal mechanism]. [Key finding 1]. [Key finding 2]. [Main uncertainty remaining].

---

## Prediction

**Most Likely Outcome:** [What will happen]

**Probability:** [X%]

**Timeframe:** [When this will occur]

**Confidence:** [High/Medium/Low]

**Reasoning:** [2-3 sentence causal explanation]

---

## Analysis Quality Metrics

| Metric | Score | Assessment |
|--------|-------|------------|
| Source Credibility | [High/Med/Low] | [N high, M medium sources] |
| Perspective Diversity | [High/Med/Low] | [N distinct frameworks] |
| Concession Rate | [X%] | [Within 15-30% target?] |
| Convergence Achieved | [X%] | [Adequate for confidence?] |
| Evidence Gaps | [N identified] | [Critical or manageable?] |

---

## Consensus Findings

### Strong Agreement (4+ personas)
- [Finding] - [Why consensus emerged]

### Moderate Agreement (3 personas)
- [Finding] - [Who dissents and why]

### No Consensus
- [Issue] - [Competing views and their logic]

---

## Causal Mechanism

**[Primary causal chain explaining WHY the predicted outcome will occur]**

This section explains the logical chain from causes to effects:

1. **Starting Condition:** [Current state]
2. **Action/Event:** [What happens]
3. **Intermediate Effects:** [Chain of consequences]
4. **Final Outcome:** [Predicted result]

**Key Assumptions:**
- [Assumption 1]
- [Assumption 2]

---

## Critical Uncertainties

**Ranked by impact on prediction:**

1. **[Uncertainty]**
   - Current state: [What we know]
   - Why it matters: [How it affects prediction]
   - Resolution path: [How to reduce uncertainty]
   - Timeline: [When will we know more?]

2. **[Uncertainty]**
   - Current state: [What we know]
   - Why it matters: [How it affects prediction]
   - Resolution path: [How to reduce uncertainty]
   - Timeline: [When will we know more?]

---

## Scenario Analysis

**Probabilities must sum to 100%**

### Base Case ([X]% probability)

**Conditions:** [What needs to be true]

**Outcome:** [What happens]

**Indicators:** [Early signals this is occurring]

### Alternative Scenario A ([Y]% probability)

**Conditions:** [What needs to be true]

**Outcome:** [What happens]

**Indicators:** [Early signals this is occurring]

### Alternative Scenario B ([Z]% probability)

**Conditions:** [What needs to be true]

**Outcome:** [What happens]

**Indicators:** [Early signals this is occurring]

**Scenario confidence:** [How stable are these probabilities?]

---

## Monitoring Framework

| Indicator | Current | Positive Signal | Negative Signal | Update Frequency |
|-----------|---------|-----------------|-----------------|------------------|
| [Metric 1] | [Value] | [Threshold] | [Threshold] | [Daily/Weekly] |
| [Metric 2] | [Value] | [Threshold] | [Threshold] | [Daily/Weekly] |
| [Metric 3] | [Value] | [Threshold] | [Threshold] | [Daily/Weekly] |

**Next Review Date:** [When to revisit this prediction]

---

## Evolution of Analysis

### Positions Eliminated (Falsified)

- **[Persona] conceded [X] to [Challenger] in Round [N]**
  - Reason: [Why position was falsified]

### Positions Strengthened (Withstood Challenges)

- **[Persona]'s view on [X] withstood challenges from [Y, Z]**

### Unresolved Cruxes

- **[Persona A] vs [Persona B]:**
  - Disagreement: [Core dispute]
  - Crux: [What would resolve it]
  - Impact: [How much does this matter for prediction?]

---

## Source Appendix

### Primary Sources (High Credibility)

- [Source] - [Date] - [Key data/claim]
- [Source] - [Date] - [Key data/claim]

### Secondary Sources (Medium Credibility)

- [Source] - [Date] - [Supporting context]
- [Source] - [Date] - [Supporting context]

### Excluded Sources

- [Source] - [Reason for exclusion: bias/unreliable/outdated]

---

## Limitations

### Scope
- [What this analysis did NOT address]

### Data
- [Time-sensitive information that may change]
- [Unavailable data that would improve analysis]

### Methodological
- [Assumptions or limitations in the analytical approach]

---

## Prediction Calibration

*(To be filled when outcome is known)*

**Original Prediction:** [What we predicted]

**Actual Outcome:** [What actually happened]

**Calibration Assessment:** [Was our confidence appropriate?]

**Learning:**
- Which analytical frameworks proved most accurate?
- Which evidence was most predictive?
- What did we miss?
```

---

## Section-by-Section Guidelines

### 1. Executive Summary (100 words max)

- Must state the prediction clearly with probability
- Include the key causal mechanism
- 2-3 key findings
- Remaining uncertainty

**Template:**
> [Question] → [Prediction] with [X% probability]. [Causal mechanism]. [Key finding 1]. [Key finding 2]. [Main uncertainty].

### 2. Prediction Section

Clear statement of what will happen, when, and with what probability.

**Components:**
- **Most Likely Outcome:** Specific prediction
- **Probability:** Numeric assessment (e.g., 65%)
- **Timeframe:** When this will occur
- **Confidence:** High/Medium/Low (based on convergence and evidence quality)
- **Reasoning:** 2-3 sentence causal explanation

### 3. Analysis Quality Metrics

| Metric | High | Medium | Low |
|--------|------|--------|-----|
| Source Credibility | 5+ high-credibility sources | 3-4 high + medium sources | <3 high sources |
| Perspective Diversity | 4+ distinct frameworks | 3 frameworks | 1-2 frameworks |
| Concession Rate | 15-30% | 10-15% or 30-40% | <10% or >40% |
| Convergence Achieved | 80%+ | 60-80% | 40-60% |
| Evidence Gaps | 0-1 manageable | 2-3 manageable | 4+ or critical |

### 4. Consensus Findings by Agreement Level

| Agreement Level | Minimum Personas | How to Handle |
|----------------|------------------|---------------|
| Strong Agreement | 4+ | Highlight as core finding |
| Moderate Agreement | 3 | Note with dissenting view |
| No Consensus | - | Present competing views |

### 5. Causal Mechanism

This is the **core of the analysis**. Explain:

1. **Starting Condition:** Current state or context
2. **Action/Event:** What will happen
3. **Intermediate Effects:** Chain of consequences
4. **Final Outcome:** Predicted result

**Key Assumptions:** What must be true for this causal chain to hold?

### 6. Critical Uncertainties (Ranked by Impact)

Rank by:
1. Impact on final prediction (higher first)
2. Resolvability (can it be reduced?)
3. Timeline (when will we know?)

For each uncertainty:
- **Current state**: What we know now
- **Why it matters**: How it affects the prediction
- **Resolution path**: How to reduce uncertainty
- **Timeline**: When will we know more

### 7. Scenario Analysis

**Scenario probabilities must sum to 100%**

| Scenario Type | Probability Range |
|---------------|-------------------|
| Base Case | 40-60% |
| Alternative A | 20-40% |
| Alternative B | 10-30% |
| Tail Risk | <10% |

Each scenario must include:
- **Conditions**: What must be true
- **Outcome**: What happens
- **Indicators**: Early signals

### 8. Monitoring Framework

**Actionable indicators only.**

For each indicator:
- **Current**: Baseline value
- **Positive Signal**: Threshold that supports the prediction
- **Negative Signal**: Threshold that contradicts the prediction
- **Update Frequency**: Daily/Weekly/Monthly

**Next Review Date**: Specific date, not "as needed"

### 9. Evolution of Analysis

**Track the debate dynamics.**

Three subsections:
1. **Positions Eliminated**: Who was falsified and why
2. **Positions Strengthened**: What withstood challenges
3. **Unresolved Cruxes**: Core disagreements that remain

### 10. Source Appendix

**Organize by credibility tier.**

| Tier | Examples |
|------|----------|
| **Primary (High)** | Central banks, government agencies, academic research |
| **Secondary (Medium)** | Major financial press, think tanks |
| **Excluded** | Social media, anonymous, partisan without corroboration |

### 11. Limitations

**Three categories:**
- **Scope**: What the analysis did NOT address
- **Data**: Time-sensitive or unavailable data
- **Methodological**: Assumptions or limitations in approach

### 12. Prediction Calibration

**To be filled when outcome is known.**

This section is for tracking prediction accuracy over time to improve future debates.

---

## Output File Location

Save to appropriate location:

| Debate Type | Save Location |
|-------------|---------------|
| Macroeconomic | `macro/overview/YYYY_MM.md` |
| Geopolitical | `macro/geopolitical/YYYY_MM_topic.md` |
| Central Bank | `macro/central_banks/fed_YYYY_MM.md` |
| Policy Analysis | `macro/theses/macro_thesis_YYYY_MM.md` |
| General Topic | `macro/[category]/[topic]_YYYY_MM_DD.md` |

---

## Minimum Requirements Checklist

Before finalizing output:

```
[ ] Executive summary <100 words with probability
[ ] Confidence level specified and justified
[ ] All 12 sections present
[ ] Scenario probabilities sum to 100%
[ ] Monitoring framework has actionable indicators
[ ] Sources organized by credibility
[ ] Limitations explicitly stated
[ ] Next review date specified
[ ] Quality scorecard passed (12/15 boxes)
```

---

## Quick Reference: Confidence Levels

See `constraints.md` for Confidence Level definitions.

| Confidence | Interpretation | Output Template |
|------------|----------------|----------------|
| **High (80%+)** | Strong causal mechanism, high convergence | "High confidence: [prediction] based on [evidence]. [Key mechanism]." |
| **Medium (60-80%)** | Clear causal path, some uncertainty | "Medium confidence: [prediction] with caveats [X, Y]." |
| **Low (40-60%)** | Multiple viable scenarios | "Low confidence: [prediction] but significant uncertainty. Key risks: [X, Y]." |
| **Research Needed (<40%)** | Insufficient evidence | "Insufficient data. Critical gaps: [X, Y]." |
